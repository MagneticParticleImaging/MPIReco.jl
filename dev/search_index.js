var documenterSearchIndex = {"docs":
[{"location":"generated/tutorials/weighting/#Weighting","page":"Weighting","title":"Weighting","text":"include(\"../../download.jl\") #hide\n\nOften time it is benefical to consider a weighted least squares problem of the form:\n\nbeginequation\n  undersetmathbfxargmin frac12vertvert mathbfSmathbfc-mathbfu vertvert^2_mathbfW + mathbfR(u) \nendequation\n\nwhere mathbfW is a symmetric, positive weighting matrix and vertvertmathbfyvertvert^2_mathbfW denotes the weighted Euclidean norm.\n\nMPIReco provides several different weighting strategies and new strategies can easily be added and plugged into existing algorithms. An example of how to implement such a strategy is shown in the How-Tos. For an overview of the available strategy consult the API reference.\n\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")) #hide\nparams = Dict{Symbol, Any}()\nparams[:SNRThresh] = 5\nparams[:frames] = 1:1\nparams[:minFreq] = 80e3\nparams[:recChannels] = 1:2\nparams[:spectralLeakageCorrection] = true\nparams[:sf] = bSF\nparams[:reg] = [L2Regularization(0.1f0)];\nnothing #hide\n\nTo apply different strategies, we simply swap out the weightingParams of our single-patch algorithm.\n\ncChannel = reconstruct(\"SinglePatch\", b; params..., weightingParams = ChannelWeightingParameters([0.8, 0.2]))\ncRow = reconstruct(\"SinglePatch\", b; params..., weightingParams = RowNormWeightingParameters())\ncWhite = reconstruct(\"SinglePatch\", b; params..., weightingParams = WhiteningWeightingParameters(whiteningMeas = bSF));\nnothing #hide\n\nWe will again visualize the reconstructions with CairoMakie:\n\nusing CairoMakie #hide\nfig = Figure();\nhidedecorations!(heatmap(fig[1, 1], cChannel[1, :, :, 1, 1].data.data, axis = (title = \"Channel\",)).axis)\nhidedecorations!(heatmap(fig[1, 2], cRow[1, :, :, 1, 1].data.data, axis = (title = \"Row Norm\",)).axis)\nhidedecorations!(heatmap(fig[1, 3], cWhite[1, :, :, 1, 1].data.data, axis = (title = \"Whitening\",)).axis)\nfig\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/gpuAcceleration/#GPU-Acceleration","page":"GPU-Acceleration","title":"GPU Acceleration","text":"include(\"../../download.jl\") #hide\ngpu = Array; #hide\nnothing #hide\n\nMPIReco supports generic GPU acceleration. This means that the user can use any GPU array type that supports the GPUArrays interface. This includes CUDA.jl, AMDGPU.jl, and Metal.jl. To perform a reconstruction on the GPU, one has to load a GPU backend package such as CUDA and specify the GPU array type:\n\nusing CUDA\ngpu = CuArray\n\nAfterwards one can use the normal reconstruction interface and specify the arrayType parameter. However, the default solver is Kaczmarz, which has poor GPU performance. One should instead use CGNR or other solver. Since those solvers usually converge slower, one also has to increase the number of iterations\n\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")) #hide\nparams = Dict{Symbol, Any}()\nparams[:SNRThresh] = 5\nparams[:frames] = 1:1\nparams[:minFreq] = 80e3\nparams[:recChannels] = 1:2\nparams[:spectralLeakageCorrection] = true\nparams[:sf] = bSF\nparams[:weightingParams] = WhiteningWeightingParameters(whiteningMeas = bSF)\nparams[:reg] = [L2Regularization(0.1f0)]\n\nSpecifying the GPU array type to use, allows reconstruction algorithm to move the system matrix and data to the GPU after frequency filtering:\n\nc = reconstruct(\"SinglePatch\", b; params..., arrayType = gpu, iterations = 100, solver = CGNR);\nnothing #hide\n\nThe resulting image is moved to the CPU at the end of the reconstruction and is accessible like any other reconstruction:\n\nusing CairoMakie\nfig = heatmap(c[1, :, :, 1, 1].data.data)\nhidedecorations!(fig.axis)\nfig\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/howtos/solvers/#Change-and-Configure-Solvers","page":"Change and Configure Solvers","title":"Change and Configure Solvers","text":"include(\"../../download.jl\") #hide\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")); #hide\nnothing #hide\n\nMPIReco uses RegularizedLeastSquares.jl as its optimization backend. As such it can use any of the solvers and regularization terms defined for and in RegularizedLeastSquares.\n\nIn general, RegularizedLeastSquares aims to solve problems of the form:\n\nbeginequation\n  undersetmathbfcargmin frac12vertvert mathbfSmathbfc-mathbfu vertvert_2^2 + + mathbfR(x)\nendequation\n\nwhere mathbfS is a system matrix operator and mathbfu is the measurement vector. Both are provided by MPIReco and constructed based on the specific parameters and processing steps of a given reconstruction algorithm. The (optional) regularization term mathbfR(x) can be used to encode additional prior information about the inverse problem. Different solvers of RegularizedLeastSquares can work with different regularization terms. For example, the Kaczmarz and CGNR solver are defined for the l^2_2-norm. More information on available solvers and regularization terms can be found RegularizedLeastSquares documentation.","category":"section"},{"location":"generated/howtos/solvers/#Solver-and-Solver-Parameters","page":"Change and Configure Solvers","title":"Solver and Solver Parameters","text":"MPIReco offers different ways to configure the used solvers, similar to how it for example offers different weighting strategies. If we take a look at the default solver parameters from the single-patch reconstruction:\n\nplan = MPIRecoPlan(\"SinglePatch\")\nsolverParams = plan.parameter.reco.solverParams\n\nWe see that the default parameters are of type ElaborateSolverParameters. These are a special set of parameters, because they contain the union of all solver parameters defined in RegularizedLeastSquares. The current selection of parameters changes based on the selected solver:\n\nsolverParams.solver = Kaczmarz\nsolverParams\n\nor:\n\nsolverParams.solver = FISTA\nsolverParams\n\nWith these parameters we can define both the solver and the solver parameters as defined in RegularizedLeastSquares.\n\nIt is also possible to add new solvers, such as variants of existing solver specialised for MPI. To do this, we have to implement a new solver variant for RegularizedLeastSquares. We can either implement a new solver or implement a new variant of a solver via its state:\n\nusing MPIReco.RegularizedLeastSquares\nmutable struct OurSolver{OP, T} <: RegularizedLeastSquares.AbstractLinearSolver\n  S::OP\n  c::Vector{T}\n  u::Vector{T}\n  notification::String\nend\nfunction OurSolver(S; notification = \"Test\", kwargs...)\n  u = zeros(eltype(S), size(S, 1))\n  c = zeros(eltype(S), size(S, 2))\n  return OurSolver(S, c, u, notification)\nend\nfunction RegularizedLeastSquares.init!(solver::OurSolver{OP, T}, u) where {OP, T}\n  solver.u .= u\n  solver.c .= zero(T)\nend\nfunction Base.iterate(solver::OurSolver)\n  @info solver.notification\n  solver.c .= solver.S \\ solver.u\n  return nothing\nend\nRegularizedLeastSquares.solversolution(solver::OurSolver) = solver.c\n\nAfterwards, we can just use the solver type as usual:\n\nparams = Dict{Symbol, Any}()\nparams[:SNRThresh] = 5\nparams[:frames] = 1:1\nparams[:minFreq] = 80e3\nparams[:recChannels] = 1:2\nparams[:spectralLeakageCorrection] = true\nparams[:sf] = bSF;\n\nc = reconstruct(\"SinglePatch\", b; params..., solver = OurSolver)\nusing CairoMakie #hide\nfig = heatmap(c[1, :, :, 1, 1].data.data)\nhidedecorations!(fig.axis)\nfig\n\nIf our custom solver requires custom parameters, we could implement custom solver parameters in MPIReco:\n\nBase.@kwdef struct OurSolverParameters <: MPIReco.AbstractSolverParameters{OurSolver}\n  notification::String\n  enforceReal::Bool=true\n  enforcePositive::Bool=true\nend\nreconstruct(\"SinglePatch\", b; params..., solverParams = OurSolverParameters(notification = \"Custom\"));\nnothing #hide\n\nMore on custom parameters for MPIReco can be found in Custom Data Processing and Algorithms.","category":"section"},{"location":"generated/howtos/solvers/#Regularization-Term","page":"Change and Configure Solvers","title":"Regularization Term","text":"RegularizedLeastSquares allows for the generartion of flexible regularization using a vector of (nested) regularization terms. By providing such a vector, we can configure the regularization term similar to the solver:\n\nsetAll!(plan, :reg, [L2Regularization(0.1)])\n\nBecause MPI oftens constrain its solutions to positive, real numbers, MPIReco offers some shortcurts to enable/disable these constraints:\n\nsetAll!(plan, :enforceReal, true)\n\nInternally, these are just additional regularization terms added to the provided regularization terms. For more complex regularization examples, take a look at the RegularizedLeastSquares documentation.\n\nTo implement a custom regularization we have to implement a proximal mapping:\n\nbeginequation\n  prox_g (mathbfx) = undersetmathbfuargmin frac12vertvert mathbfu-mathbfx vert vert^2 + g(mathbfx)\nendequation\n\nFor many regularizers, the proximal map can be computed efficiently in a closed form.\n\nIn order to implement these proximal mappings, we have to defines the following type functions for our new proximal map:\n\nabstract type AbstractRegularization\nprox!(reg::AbstractRegularization, x)\nnorm(reg::AbstractRegularization, x)\n\nHere prox!(reg, x) is an in-place function which computes the proximal map on the input-vector x. The function norm computes the value of the corresponding term in the inverse problem. RegularizedLeastSquares.jl provides AbstractParameterizedRegularization and AbstractProjectionRegularization as core regularization types.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/explanations/operators/#Imaging-Operators","page":"Imaging Operators","title":"Imaging Operators","text":"using MPIReco #hide\n\nThe system-matrix based image reconstruction algorithms provided by MPIReco mainly focus on inverse problems of the form:\n\nbeginequation\n  undersetmathbfcargmin frac12vertvert mathbfSmathbfc-mathbfu vertvert_2^2 + + mathbfR(x)\nendequation\n\nwhere mathbfS is a system matrix, mathbfu is the measurement vector, and mathbfR(x) is an (optional) regularization term. In this explanation we will take a closer look at the requirements on mathbfS, which is especially relevant if one wants to implement a hybrid- or model based operator for the inverse problem.\n\nS = randn(256, 256)\nc = randn(256)\nu = S*c;\nnothing #hide","category":"section"},{"location":"generated/explanations/operators/#Linear-Algebra","page":"Imaging Operators","title":"Linear Algebra","text":"Different solvers require different interaction with the system matrix mathbfS. Kaczmarz itself uses a dot product with the rows of mathbfS and the current approximate solution mathbfc. Since there is no predefined function for such an operation, RegularizedLeastSquares.jl implemented its own\n\nusing MPIReco.RegularizedLeastSquares\nrow = 1\nisapprox(RegularizedLeastSquares.dot_with_matrix_row(S, c, row), sum(S[row, :] .* c))\n\nCustom operators should implement efficient variants of this function to ensure good performance with the Kaczmarz solver. Since Julia is a column-major order language, this row-based access pattern is quite inefficient for dense arrays. A workaround is to transpose the matrix then pass it to a Kaczmarz solver.\n\nS_efficient = transpose(collect(transpose(S)))\ntypeof(S_efficient)\n\nRegularizedLeastSquares provides an efficient implmentation for this operator.\n\nOther solvers such as FISTA or CGNR require the normal operator of mathbfS, either because they require the gradient of the least squares norm or because the work on an adapted optimization problem. The normal operator mathbfS^*S is composed of a matrix-vector product of mathbfS followed by matrix-vector product of the adjoint of mathbfS. An efficient matrix-vector product is provided in Julia by the LinearAlgebra standard library:\n\nusing LinearAlgebra\nmul!(u, S, c)\nisapprox(u, S * c)\n\nThis inplace variant of a matrix-vector product is used within in RegularizedLeastSquares and also needs to be provided for custom operators.","category":"section"},{"location":"generated/explanations/operators/#Matrix-Free","page":"Imaging Operators","title":"Matrix-Free","text":"LinearAlgebra also provides a function to compute the adjoint of a matrix-vector product:\n\nmul!(c, adjoint(S), u)\nisapprox(c, adjoint(S) * u)\n\nThis function creates a lazy adjoint, i.e. it does not create a new array. Instead it only changes the way the size and indexing into the underyling array works.\n\nS_adj = adjoint(S)\n\nA related concepts are matrix-free operators. These are operators which behave like a matrix in a(n adjoint) matrix-vector product, but don't have an underlying dense matrix.\n\nThere are several different Julia packages with which one can create such matrix-free operators such as LinearOperators.jl or LinearMaps.jl. MPIReco uses the LinearOperatorCollection.jl package to create matrix-free operators for and with mathbfS.\n\nusing MPIReco.LinearOperatorCollection\nweights = rand(256)\nwop = WeightingOp(weights)\nsize(wop)\n\nFor example, LinearOperatorCollection provides a weighting operator. This operator acts as if it is a diagonal matrix, but only requires the elements of the diagonal. We can also do matrix-free matrix product to create mathbfWS without calculating the matrix-matrix product:\n\nWS = ProdOp(wop, S)\nisapprox(WS * c, weights .* S * c)\n\nAnother relevant matrix-free operator is the normal operator:\n\nSHS = normalOperator(WS)\n\nThis operator not only computes its matrix-vector product in a lazy fashion, it also optimizes the resulting operator: Without an optimization a matrix-free product would apply the following operator each iteration:\n\nbeginequation\n  (mathbfWS)^*mathbfWS = mathbfS^*mathbfW^*mathbfWmathbfS\nendequation\n\nThis is not efficient and instead the normal operator can be optimized by initially computing the weights:\n\nbeginequation\n  tildemathbfW = mathbfW^*mathbfW\nendequation\n\nand then applying the following each iteration:\n\nbeginequation\n  mathbfS^*tildemathbfWmathbfS\nendequation\n\nAnd lastly, the efficient multi-patch image reconstruction is based on a matrix-free multi-patch operator. This operator contains system matrices per patch as well as indexing metadata and is able to act like a large dense matrix in a matrix-vector product and can be combined with weighting and the normal operator.","category":"section"},{"location":"generated/explanations/operators/#GPU-Acceleration","page":"Imaging Operators","title":"GPU Acceleration","text":"GPU acceleration is achieved by adapting mathbfS and mathbfu to be GPU-compatible data types. In the case of dense arrays, this means the arrays are GPU arrays.\n\nMatrix-free operators on the other hand don't necessarily need to be on the GPU. In the case that a matrix-free operator is only a function call, this function only needs to be GPU compatible. In the case of the weighting operator or the matrix-free operator, we need to move the internally used dense arrays to the GPU and can then use them on the GPU.\n\nTo make more complex operators work on the GPU one can either try to formulate a method on GPUArrays which only uses broadcasts. Or alternatively implement a custom GPU kernel with either a specific GPU package such as CUDA.jl or AMDGPU.jl or a vendor-agnostic kernel using KernelAbstractions.jl.\n\nA related Julia package is also the Adapt.jl, which offers the adapt method. This essentially acts like convert(T, a) without the restriction that the result must be of type T. The use case for GPU computing here is to provide the GPU array type T and then return a GPU compatibe version of a, however that might look like.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"recoResults/#Reconstruction-Results","page":"Reconstruction Results","title":"Reconstruction Results","text":"The object c is of type ImageMeta and contains not only the reconstructed data but also several metadata such as the reconstruction parameters being used. c has in total 5 dimensions. The first dimension encodes multi-spectral channels. Dimensions 2-4 encode the three spatial dimensions. The last dimension contains the number of frames being stored in c.","category":"section"},{"location":"literate/lowlevel/","page":"-","title":"-","text":"Finally, we have arrived at the low level reconstruction routine that has the signature\n\nfunction reconstruction(S, u::Array; sparseTrafo = nothing,\n                        lambd=0, progress=nothing, solver = \"Kaczmarz\",\n                        weights=nothing, kargs...)\n\nOne can see that it requires the system matrix S and the measurements u to be already loaded.\n\nWe note that S is typeless for a reason here. For a regular reconstruction one will basically feed in an Array{ComplexF32,2} in here, although more precisely it will be a Transposed version of that type if the Kaczmarz algorithm is being used for efficiency reasons.\n\nHowever, in case that matrix compression is applied S will be of type SparseMatrixCSC. And for Multi-Patch Reconstruction S will be of type MultiPatchOperator. Hence, the solvers are implemented in a very generic way and require only certain functions to be implemented. The low level reconstruction method calls one of the solvers from RegularizedLeastSquares.jl.","category":"section"},{"location":"generated/tutorials/multiPatch/#Multi-Patch-Reconstruction","page":"Multi-Patch","title":"Multi-Patch Reconstruction","text":"include(\"../../download.jl\") #hide\n\nFor multi-patch reconstruction the method proposed by Szwargulski et al. is implemented in MPIReco. It is generalized however as described in Boberg et al..\n\nWe first discuss the measurements for the multi-patch case. On modern MPI scanners the BrukerFile or MDFFile can be used as is. However, the data that we use in our unit tests consists of several single-patch measurements. We therefore combine them manually into an MultiMPIFile:\n\nusing MPIReco #hide\nfiles = [\"1.mdf\", \"2.mdf\", \"3.mdf\", \"4.mdf\"]\nb = MultiMPIFile(joinpath.(datadir, \"measurements\", \"20211226_203916_MultiPatch\", files))\n\nAnd now b can be used as if it was a multi-patch file.\n\nNext we take a look at the system matrix. The most simple approach is to use a single system matrix that was measured at the center. This can be done using\n\nbSF = MultiMPIFile([joinpath(datadir, \"calibrations\", \"12.mdf\")])\n\nAfterwards we can perform a reconstruction with\n\nc1 = reconstruct(\"MultiPatch\", b; sf = bSF, SNRThresh=5, frames=1:acqNumFrames(b), minFreq=80e3,\n                   recChannels=1:rxNumChannels(b), iterations=1, spectralLeakageCorrection=false, tfCorrection = false);\nnothing #hide\n\nThe parameters are essentially the same as in the previous reconstructions, we only change the algorithm and the MPIFiles.\n\nIt is also possible to use multiple system matrices, which is currently the best way to take field imperfection into account. Our test data has four patches and we therefore can use\n\nsf_files =  [\"8.mdf\", \"9.mdf\", \"10.mdf\", \"11.mdf\"]\nbSFs = MultiMPIFile(joinpath.(datadir, \"calibrations\", sf_files))\n\nc2 = reconstruct(\"MultiPatch\", b; sf = bSFs, SNRThresh=5, frames=1:acqNumFrames(b), minFreq=80e3,\n                   recChannels=1:rxNumChannels(b), iterations=1, spectralLeakageCorrection=false, tfCorrection = false);\nnothing #hide\n\nNow we want somewhat more flexibility and\n\ndefine a mapping between the system matrix and the patches, here we allow to use the same system matrix for multiple patches\nmake it possible to change the FFP position. Usually the value stored in the file is not 100% correct due to field imperfections.\n\nTo achieve this, we swap out parts of the MultiPatch blueprint with a parameter which allows us to explicitly set all these parameters\n\nWe perform our own frequency filtering.\n\nfreq = filterFrequencies(bSFs, SNRThresh=5, minFreq=80e3);\nnothing #hide\n\nAnd load four different system matrices for each patch.\n\nS = [getSF(SF,freq,nothing,\"Kaczmarz\", bgcorrection=false, tfCorrection = false)[1] for SF in bSFs]\n\nAfterwards we can describe our patch mapping and positions:\n\nmapping = [1,2,3,4]\nSFGridCenter = zeros(3,4)\nFFPos = zeros(3,4)\nFFPos[:,1] = [-0.008, 0.008, 0.0]\nFFPos[:,2] = [-0.008, -0.008, 0.0]\nFFPos[:,3] = [0.008, 0.008, 0.0]\nFFPos[:,4] = [0.008, -0.008, 0.0];\nnothing #hide\n\nLastly, we wrap everything in a parameter structs:\n\nopParams = ExplicitMultiPatchParameter(;tfCorrection = false, systemMatrices = S, SFGridCenter = SFGridCenter, mapping = mapping)\nffPos = CustomFocusFieldPositions(FFPos);\nnothing #hide\n\nand perform our reconstruction:\n\nc3 = reconstruct(\"MultiPatch\", b; sf = bSFs, opParams = opParams, ffPos = ffPos, ffPosSF = ffPos,\n                  SNRThresh=5, frames=1:acqNumFrames(b), minFreq=80e3,\n                  recChannels=1:rxNumChannels(b), iterations=1, spectralLeakageCorrection=false, tfCorrection = false);\nnothing #hide\n\nWe can again visualize our different multi-patch reconstructions:\n\nusing CairoMakie #hide\nfig = Figure();\nhidedecorations!(heatmap(fig[1, 1], c1[1, :, :, 1, 1].data.data, axis = (title = \"Single SM\",)).axis)\nhidedecorations!(heatmap(fig[1, 2], c2[1, :, :, 1, 1].data.data, axis = (title = \"Multiple SM\",)).axis)\nhidedecorations!(heatmap(fig[1, 3], c3[1, :, :, 1, 1].data.data, axis = (title = \"Explicit SM\",)).axis)\nfig\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"parameters/#Parameters","page":"Parameters","title":"Parameters","text":"","category":"section"},{"location":"parameters/#math","page":"Parameters","title":"```math","text":"","category":"section"},{"location":"parameters/#\\begin{equation}","page":"Parameters","title":"\\begin{equation}","text":"","category":"section"},{"location":"parameters/#\\underset{\\mathbf{x}}{argmin}-\\frac{1}{2}\\vert\\vert-\\mathbf{S}\\mathbf{c}-\\mathbf{u}-\\vert\\vert_22-\\mathbf{R(x)}","page":"Parameters","title":"\\underset{\\mathbf{x}}{argmin} \\frac{1}{2}\\vert\\vert \\mathbf{S}\\mathbf{c}-\\mathbf{u} \\vert\\vert_2^2 + + \\mathbf{R(x)}","text":"","category":"section"},{"location":"parameters/#\\end{equation}","page":"Parameters","title":"\\end{equation}","text":"","category":"section"},{"location":"parameters/#","page":"Parameters","title":"```","text":"","category":"section"},{"location":"generated/howtos/extensions/#Implement-Reconstruction-Packages","page":"Implement Reconstruction Packages","title":"Implement Reconstruction Packages","text":"In the Custom Data Processing and Algorithms how-to, we showed how to create custom parameters, processing steps and algorithms. We also showed that we can create empty RecoPlans with new custom structures. The only thing missing to fully make such blueprints available to the usual MPIReco interface is to essentially tell MPIReco about our custom structures and blueprints.\n\nLet's implement a small Julia package for our weighting strategy:\n\nmodule CustomWeighting\n  using MPIReco\n  using MPIReco.AbstractImageReconstruction\n\n  export AlternatingWeightingParameters\n  Base.@kwdef struct AlternatingWeightingParameters <: AbstractWeightingParameters\n    alternatingWeights::Vector{Float64}\n  end\n\n  function AbstractImageReconstruction.process(::Type{<:AbstractMPIRecoAlgorithm}, params::AlternatingWeightingParameters, freqs::Vector{CartesianIndex{2}}, args...)\n    alternatingWeights = Iterators.cycle(params.alternatingWeights) # Infinitely cycle through our weights\n    weights = collect(Iterators.take(alternatingWeights, length(freqs)))\n    return weights\n  end\nend\n\nTo use this module, a user could simply import both MPIReco and CustomWeighting:\n\nusing MPIReco, .CustomWeighting\nplan = MPIRecoPlan(\"SinglePatch\")\nsetAll!(plan, :weightingParams, AlternatingWeightingParameters(collect(range(0.0, 1.0, length=5))))\n\nHowever, they won't be able to do something like\n\nreconstruct(\"SinglePatchAlternating\", b; kwargs...)\n\njust yet.\n\nWe first have to store a blueprint in some directory dir. This could be an directory within our CustomWeighting package or an expected folder in the users filesystem. Secondly, we need to tell MPIReco which modules it should consider when loading a blueprint. We can do both these things in the initialization function of our package:\n\nmodule CustomWeighting\n  # ... same code as above\n\n  dir = joinpath(@__DIR__(), \"..\", \"Plans\")\n  function __init__()\n    addRecoPlanPath(dir)\n    addRecoPlanModule(CustomWeighting)\n  end\nend\n\nAfterwards a user can simply invoke our reconstruction algorithms just like they would the provided reconstruction algorithms.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/lowlevel/#Low-Level-Reconstruction","page":"Low-Level","title":"Low-Level Reconstruction","text":"include(\"../../download.jl\") #hide\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")) #hide\n\nIn low-level reconstruction we manually supply both the system matrix mathbfS and the preprocessed measurement vector mathbfu. As an example we will reproduce a high-level reconstruction with the low-level interface:\n\nparams = Dict{Symbol, Any}()\nparams[:SNRThresh] = 5\nparams[:sf] = bSF\nparams[:frames] = 1:acqNumFrames(b)\nparams[:minFreq] = 80e3\nparams[:recChannels] = 1:rxNumChannels(b)\nparams[:iterations] = 1\nparams[:spectralLeakageCorrection] = true;\nparams[:reg] = [L2Regularization(0.0f0)]\n\n\ncHigh = reconstruct(\"SinglePatch\", b; params...);\nnothing #hide\n\nWhile it is possible to manually invoke the processing steps involved in an algorithms reconstruction, we will instead call the respective procsesing functions of MPIFiles to prepare mathbfu:\n\nfreqs = filterFrequencies(bSF, SNRThresh = 5, minFreq = 80e3, recChannels = 1:rxNumChannels(b))\nu = getMeasurementsFD(b, frames = 1:acqNumFrames(b), frequencies = freqs, spectralLeakageCorrection=true)\n\nAnd afterwards use MPIRecos utility functions to prepare mathbfS:\n\nsparseTrafo = nothing\nS, grid = getSF(bSF, freqs, sparseTrafo, Kaczmarz)\ntypeof.([S, grid])\n\nNow we can configur a low-level reconstruction:\n\ncLow = reconstruct(\"LowLevel\", u; S = S, iterations = params[:iterations], reg = params[:reg])\n\nNote that the low-level reconstruction returns a matrix without any metadata unlike the other reconstructions. The second dimension of the result matrix are the frames. To compare and plot our data we have to reshape it:\n\nsliceLow = sliceLow = reshape(cLow[:, 1], Tuple(grid.shape))\nusing CairoMakie #hide\nfig = Figure();\nhidedecorations!(heatmap(fig[1, 1], cHigh[1, :, :, 1, 1].data.data, axis = (title = \"High\",)).axis)\nhidedecorations!(heatmap(fig[1, 2], sliceLow[:, :, 1], axis = (title = \"Low\",)).axis)\nfig\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/multiContrast/#Multi-Contrast-Reconstruction","page":"Multi-Contrast","title":"Multi-Contrast Reconstruction","text":"include(\"../../download.jl\") #hide\n\nSo far we have discussed single-contrast reconstructions of the form:\n\nbeginequation\n  undersetmathbfcargmin frac12vertvert mathbfSmathbfc-mathbfu vertvert_2^2 + + mathbfR(x)\nendequation\n\nwhere mathbfS is a single system matrix, mathbfu is the measurement vector, and mathbfR(x) is an (optional) regularization term. In a multi-contrast reconstruction one can use two or more system matrices to solve:\n\nbeginequation\n   undersetc1c2argmin frac12left mathbfS_1S_2 beginpmatrix mathbfc_1  mathbfc_2 endpmatrix - mathbfu right_2^2 + mathbfR(x)\nendequation\n\nTo apply this technique to our algorithms, we simply have to provide multiple system matrices to our reconstructions:\n\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")) #hide\nbContrast = MultiContrastFile([bSF, bSF])\n\nand can then reconstruct as usual:\n\nc = reconstruct(\"SinglePatch\", b;\n                   SNRThresh=5,\n                   sf = bContrast,\n                   frames=1:acqNumFrames(b),\n                   minFreq=80e3,\n                   recChannels=1:rxNumChannels(b),\n                   iterations=1,\n                   spectralLeakageCorrection=true);\nsize(c)\n\nNote that c now has two entries in its first dimension, one for each contrast.\n\nWe can then just simply access the data of each contrast by accessing the specific dimensions:\n\nusing CairoMakie #hide\nfig = Figure();\nhidedecorations!(heatmap(fig[1, 1], c[1, :, :, 1, 1].data.data, axis = (title = \"Contrast 1\",)).axis)\nhidedecorations!(heatmap(fig[1, 2], c[2, :, :, 1, 1].data.data, axis = (title = \"Contrast 2\",)).axis)\nfig\n\nIn this case the channels are identical, because we reused the same system matrix.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/explanations/recoplans/#MPIRecoPlans","page":"MPIRecoPlan","title":"MPIRecoPlans","text":"using MPIReco #hide\n\nIn this explanation we focus on the blueprint mechanism RecoPlans of AbstractImageReconstruction and how these are used in MPIReco. We start with a quick recap of the RecoPlan interface and then see how MPIReco uses it.","category":"section"},{"location":"generated/explanations/recoplans/#RecoPlans","page":"MPIRecoPlan","title":"RecoPlans","text":"RecoPlans are blueprints from which parameters and algorithms can be constructed. They are essentially thin-wrappers around nested-key value pairs. Plans are able to represent the nested tree structure of algorithms and their parameters. A plan can either be empty, partially or fully parameterized. Empty plans are helpful to describe just the structure of an algorithm, which a user can then parameterize. If a plan is constructed this way, it is missing all parameters:\n\nusing MPIReco.AbstractImageReconstruction\nplan = RecoPlan(CommonPreProcessingParameters)\nplan.frames\n\nWe can interact with the plan as if it were a mutable variant of the given parameters:\n\nplan.frames = 1:10\nplan.bgParams = NoBackgroundCorrectionParameters()\nplan\n\nAnd we can construct instances of parameters and algorithms from a plan:\n\nparameter = build(plan)\n\nLikewise we can go from an instance to a plan via:\n\nplan = toPlan(parameter)\n\nWe can either manually empty a plan from its parameters:\n\nplan.frames = missing\n\nOr use the clear! method, which preserves the structure of a blueprint by default:\n\nclear!(plan)\n\nRecoPlans can be written to and read from files:\n\nplan.frames = 1:42\nplan.loadasreal = true\nplan.numAverages = rand(1:100)\ntoTOML(stdout, plan) #hide\ntoTOML(joinpath(@__DIR__, \"Parameters.toml\"), plan)\n\nThis way one can either serialize a completely parametrized image reconstruction or just the blueprint of an algorithm.\n\nFor more information on RecoPlans, we refer to the How-to section of the AbstractImageReconstruction documentation.","category":"section"},{"location":"generated/explanations/recoplans/#MPIRecoPlan","page":"MPIRecoPlan","title":"MPIRecoPlan","text":"MPIReco facilitates access to RecoPlans via two additional features. The first features deals with loading RecoPlans. To load a RecoPlan from a file one has to provide the filename and a list of modules in which the respective algorithms and parameters are defined. MPIReco tracks a list of directories and modules to grant a user easier access to plans contained within the directories.\n\nAs was shown in the Implement Reconstruction Packages how-to, it is possible to register new modules and directory to MPIReco:\n\naddRecoPlanPath(@__DIR__())\nplan = MPIRecoPlan(joinpath(@__DIR__, \"Parameters\"))\n\nThe second feature was shown in the Enable Caching how-to. This feature is realized by MPIReco keeping a least-recently-used (LRU) cache for recently opened plans. As long as the plan structure was not changed in the file or the parameters, a plan can be reused from the cache. While this also saves costs in loading a plan, the main benefit is reusing the same plan instance. If the plan in question contains processing steps that implement caching, all algorithms derived from a plan can access this cache. This enables an algorithm to reuse the results of previous processing steps.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"references/parameters/#Parameters","page":"Parameters","title":"Parameters","text":"","category":"section"},{"location":"references/parameters/#Weighting","page":"Parameters","title":"Weighting","text":"","category":"section"},{"location":"references/parameters/#Background-Correction","page":"Parameters","title":"Background Correction","text":"","category":"section"},{"location":"references/parameters/#System-Matrix","page":"Parameters","title":"System Matrix","text":"","category":"section"},{"location":"references/parameters/#Least-Squares","page":"Parameters","title":"Least-Squares","text":"","category":"section"},{"location":"datasetStore/#Layers","page":"-","title":"Layers","text":"The reconstruction function has several layers starting from a high level over several middle layer to low layer functions. The most high level method has the following signature `julia reconstruction(dMDFDatasetStore studyStudy expExperiment recoParamsDictStringAny)","category":"section"},{"location":"generated/howtos/custom/#Custom-Data-Processing-and-Algorithms","page":"Implement Custom Data Processing","title":"Custom Data Processing and Algorithms","text":"include(\"../../download.jl\") #hide\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")); #hide\nnothing #hide\n\nThis how-to provides a quick guide on how to customize reconstruction algorithms. For more information on how to extend algorithms and processing steps, we refer to the Explanations section of the documentation and to the example section of AbstractImageReconstructions documentation.","category":"section"},{"location":"generated/howtos/custom/#Custom-Processing-Steps","page":"Implement Custom Data Processing","title":"Custom Processing Steps","text":"To implement a custom processing step, we need to add a new parameter struct, in our case we want to extend AbstractWeightingParameters. As a toy-example, we will implement a weighting strategy in which frequencies are weighting with an alternating sequence of weights:\n\nBase.@kwdef struct AlternatingWeightingParameters <: AbstractWeightingParameters\n  alternatingWeights::Vector{Float64}\nend\n\nThe Base.@kwdef macro generates a keyword-argment constructor with optional default values. Next, we can implement the actual processing function.\n\nDifferent algorithms can have different implementations of a given weighting strategy and we can specialise a function on the type of algorithm or an algorithm instance itself. The former is helpful for pure functions, i.e. processing steps which solely depend on the given parameter and processing-arguments, not the state of the algorithm. The generic weight-process function takes as input the frequencies and the system matrix operator. In our case we only require the frequencies:\n\nfunction AbstractImageReconstruction.process(::Type{<:AbstractMPIRecoAlgorithm}, params::AlternatingWeightingParameters, freqs::Vector{CartesianIndex{2}}, args...)\n  alternatingWeights = Iterators.cycle(params.alternatingWeights) # Infinitely cycle through our weights\n  weights = collect(Iterators.take(alternatingWeights, length(freqs)))\n  return weights\nend\n\nAfter implementing our processing function, we can directly use it within our exisintg algorithm blueprints:\n\nparams = Dict{Symbol, Any}()\nparams[:SNRThresh] = 5\nparams[:frames] = 1:1\nparams[:minFreq] = 80e3\nparams[:recChannels] = 1:2\nparams[:spectralLeakageCorrection] = true\nparams[:sf] = bSF\nparams[:reg] = [L2Regularization(0.1f0)]\n\nourWeighting = AlternatingWeightingParameters(collect(range(0.0, 1.0, length=5)))\n\nWe can use either the high-level interface:\n\nc1 = reconstruct(\"SinglePatch\", b; params..., weightingParams = ourWeighting);\nnothing #hide\n\nOr the RecoPlan interface:\n\nplan = MPIRecoPlan(\"SinglePatch\")\nsetAll!(plan, params)\nsetAll!(plan, :weightingParams, ourWeighting)\nalgo = build(plan)\nc2 = reconstruct(algo, b)\nisapprox(c1.data.data, c2.data.data)\n\nWe can visualize the results of our weighting:\n\nusing CairoMakie\nfig = heatmap(c1[1, :, :, 1, 1].data.data)\nhidedecorations!(fig.axis)\nfig\n\nThe SinglePatch algorithm which we adapted with our new weighting strategy, actually allows weighting results to be cached.\n\nplan = MPIRecoPlan(\"SinglePatch\")\ntypeof(plan.parameter.reco.weightingParams)\n\nBy overwritting the weightingParams, we removed the caching layer. If we want to use our adapted reconstruction algoritm with the best performace, we have to retain the caching layer:\n\nplan.parameter.reco.weightingParams.param = ourWeighting\nsetAll!(plan, params)\nalgo = build(plan)\nc3 = reconstruct(algo, b)\nisapprox(c1.data.data, c3.data.data)\n\nWe can then turn out algorithm into a plan and store it somewhere:\n\nplan = toPlan(algo)\nAbstractImageReconstruction.clear!(plan)\ntoTOML(stdout, plan)\n\nThe How-to on Implement Reconstruction Packages shows to make such a plan available to the usual MPIReco interfaces.","category":"section"},{"location":"generated/howtos/custom/#Custom-Reconstruction-Algorithms","page":"Implement Custom Data Processing","title":"Custom Reconstruction Algorithms","text":"So far, we created new \"variant\" of an image reconstruction algorithm by adding a new strategy of an existing processing step. However, if our new reconstruction algorithm requires overall different data processing, such as for example an X-space reconstruction, we need to implement a new AbstractMPIRecoAlgorithm.\n\nThe AbstractImageReconstruction.jl documentation has examples of full algorithm implementations. We recommend reading those and then reading the implementation of the single-patch reconstruction algorithm as a starting point.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/distributed/#Distributed-Image-Reconstruction","page":"Distributed Reconstruction","title":"Distributed Image Reconstruction","text":"include(\"../../download.jl\") #hide\n\nMPIReco image reconstructions can also be executed across different computers, thanks to DaggerImageReconstruction. With this feature one could perform a reconstruction over the network on a machine with some specific resource, be it a specific system matrix or access to a GPU.\n\nTo enable a distributed reconstruction one has to first use the Distributed standard library to add a new Julia process on the remote machine.\n\nusing Distributed\nworkers = addprocs([\"remote_address])\nworker = first(workers)\n\nusing Distributed #hide\nworker = 1 #hide # comment out to properly connect to a different process\n\nThe worker is the Julia process id, which is used to identify where to move data to and perform computations on. Afterwards we just load both MPIReco and DaggerImageReconstruction:\n\nusing MPIReco, DaggerImageReconstruction\n\nInstead of a MPIFile, we now want to create a DMPIFile, a distributed MPIFIle. Such a file expects a path on the remote machine together with the worker id:\n\ndistr_bSF = DMPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\"), worker = worker)\ndistr_b = DMPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\"), worker = worker)\n\nNote that you might need to consider differences between the operating systems of both machines. For example, in this case we constructing our filepath locally, while evaluating it on the remote. You could also construct the path on the worker with:\n\nremotecall_fetch(() -> joinpath(\"...\"), worker)\n\nOnce we have our distributed files, we can configure our reconstruction like usual and the algorithm figures out on which worker to execute based on the provided distributed MPIFiles. In this case, both files were located on the remote. If the measurements are located on the local machine, then one has to transfer the data over the network.\n\nc1 = reconstruct(\"SinglePatch\", distr_b;\n                   SNRThresh=5,\n                   sf = distr_bSF,\n                   frames=1:acqNumFrames(distr_b),\n                   minFreq=80e3,\n                   recChannels=1:rxNumChannels(distr_b),\n                   iterations=1,\n                   spectralLeakageCorrection=true);\nnothing #hide\n\nMost MPIFiles instances are just handles to one or more local files and thus can't be meaningfully send over the network. To get around this, you can transform an MDF into an MDFinMemory, which is a fully in-memory representation of an MDF.\n\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\"))\nbInMemory = MDFv2InMemory(b)\n\nNow the algorithm can't determinte the worker from the measurement anymore and we have to utilize the loadDaggerPlan function from DaggerImageReconstruction. This function expects a path to a local RecoPlan, which is then constructed on the given worker:\n\nplanpaths = getRecoPlanList(;full=true)\nindex = findfirst(endswith(\"SinglePatch.toml\"), planpaths)\ndistr_plan = loadDaggerPlan(planpaths[index], getRecoPlanModules(), worker = 1)\n\nWe can then configure the plan as usual:\n\nsetAll!(distr_plan; SNRThresh=5,\n                   sf = distr_bSF,\n                   frames=1:acqNumFrames(bInMemory),\n                   minFreq=80e3,\n                   recChannels=1:rxNumChannels(bInMemory),\n                   iterations=1,\n                   spectralLeakageCorrection=true)\n\nAnd perform a normal reconstruction with it:\n\ndistr_algo = build(distr_plan)\nc2 = reconstruct(distr_algo, bInMemory)\nisapprox(c1.data.data, c2.data.data)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"references/multipatch/#Multi-Patch-Algorithms","page":"Multi-Patch","title":"Multi-Patch Algorithms","text":"","category":"section"},{"location":"references/singlepatch/#Single-Patch-Algorithms","page":"Single-Patch","title":"Single-Patch Algorithms","text":"","category":"section"},{"location":"references/utility/#Utility-Functions","page":"Utility","title":"Utility Functions","text":"","category":"section"},{"location":"generated/howtos/callbacks/#Callbacks","page":"Use Callbacks","title":"Callbacks","text":"include(\"../../download.jl\") #hide\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")); #hide\nnothing #hide\n\nRegularizedLeastSquares provides a callback mechanism that allows you to access and monitor the state of the optimization process. These callbacks are invoked at the start of each iteration and have the form f(solver, iteration). Via the solver, you can access any internal property of the solver state.\n\nMPIReco exposes this interface for compatible algorithms. You can use do-syntax to pass a callback of the form f(solver, frame, iteration) to the reconstruction:\n\nparameters = Dict{Symbol, Any}() #hide\nparameters[:SNRThresh] = 5 #hide\nparameters[:sf] = bSF #hide\nparameters[:frames] = 1:acqNumFrames(b) #hide\nparameters[:minFreq] = 80e3 #hide\nparameters[:recChannels] = 1:rxNumChannels(b) #hide\nparameters[:iterations] = 3 #hide\nparameters[:spectralLeakageCorrection] = true; #hide\nc = reconstruct(\"SinglePatch\", b; parameters...) do solver, frame, iteration\n  tmp = sum(solversolution(solver))\n  @info \"Sum of concentration at frame $frame and iteration $iteration is $tmp\"\nend\n\nMPIReco also provides built-in callbacks that can store the solution in each iteration or compare the current solution with a reference:\n\ncb = StoreSolutionPerFrameCallback()\nreconstruct(cb, \"SinglePatch\", b; parameters...);\ncb.solutions[1]\n\nYou can also combine multiple callbacks:\n\ncb1 = StoreSolutionPerFrameCallback()\nref = reshape(c[1, :, :, :, 1].data.data, :, 1)\ncb2 = CompareSolutionPerFrameCallback(ref)\nreconstruct(\"SinglePatch\", b; parameters...) do solver, frame, iteration\n  cb1(solver, frame, iteration)\n  cb2(solver, frame, iteration)\nend\ncb2.results[1]\n\nNote that callbacks are used directly in the solver and thus reflect its value domain. This means that in sparse reconstruction, the current solution approximation is not in the image domain. Likewise, the solution might still be a complex number.\n\nBoth variants shown above get passed as a callbacks keyword argument to the algorithm. When using the callback directly like this, the interface changes from f(solver, frame, iteration) to f(solver, iteration). And you have to manually differentiate between frames by watching for the start of a new reconstruction:\n\nframe = 0\nfunction my_callback(solver, iteration)\n  if iteration == 0\n    global frame += 1\n  end\n  @info \"Frame $frame, Iteration $iteration\"\nend\nreconstruct(\"SinglePatch\", b; parameters..., callbacks = my_callback);\nnothing #hide\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/overview/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"To begin, we first need to gather some MPI data. To do this we could use data from the OpenMPIData initiative, however for these examples we will use the data used in testing MPIReco.\n\nTo access this test data, first, enter the Pkg mode in Julia (]) and execute the unit tests of MPIReco::\n\ntest MPIReco\n\nThis will download and unpack some MPI measurements and calibration MDF files and perform tests with the data. The download location will be printed at the start of the test execution. You can cancel the test execution once the data is downloaded by pressing Ctrl + C or closing the Julia process.\n\nAfter the download, several MPI files will be present in the specified directory. All subsequent examples assume that you have assigned the path to this directory to a variable named datadir:\n\ninclude(\"../../download.jl\"); #hide\nnothing #hide\n\nconst datadir = joinpath(\"...\",\"artifacts\", \"...\") # enter path here","category":"section"},{"location":"generated/tutorials/overview/#First-Reconstruction","page":"Getting Started","title":"First Reconstruction","text":"We will start looking at a small reconstruction script. First, we load MPIReco:\n\nusing MPIReco\n\nNext, we open handles for the system matrix and measurement data. Both are created via MPIFile function, which can be, for instance, an MDFFile or a BrukerFile.\n\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\"))\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\"))\n\nTo interact with the files, you can use the functionality of MPIFiles, which is also exported by MPIReco:\n\nacqNumFrames(b)\n\nWe refer to the documentation for MPIFiles.jl and MDF for more information on the available data and functions.\n\nNow we will perform a system-matrix based reconstruction using the reconstruct function. The function takes as arguments the algorithm to use, the measurement data, and various keyword arguments. The available parameters and their interpretation depend on the chosen algorithm. In this case, the algorithm also expects the system matrix to be set. We set the SNR threshold to 5, meaning that only matrix rows with an SNR above 5 will be used during reconstruction. The parameter frame decides which frame of the measured data should be reconstructed.\n\nc = reconstruct(\"SinglePatch\", b;\n                   SNRThresh=5,\n                   sf = bSF,\n                   frames=1:acqNumFrames(b),\n                   minFreq=80e3,\n                   recChannels=1:rxNumChannels(b),\n                   iterations=1,\n                   spectralLeakageCorrection=true)\n\nNotice that the result is not just an array of particle concentration, but contains a variety of metadata as well. This is because c is a:\n\ntypeof(c)\n\nYou can access metadata as properties, such as:\n\nc.tracerName\n\nThe result can also be treated like a normal 5-dimensional array. The first dimension is for different contrasts, followed by the three spatial dimensions and lastly the temporal dimension of the different frames.\n\nsize(c)\n\nYou can access the underlying data just like any other array in Julia. For example, you can access an XY slice as follows:\n\nslice = c[1, :, :, 1, 1]\ntypeof(slice)\n\nNote that the slice is still an ImageMeta array. Inside the array is an AxisArray, another array type with metadata. Not every Julia package has methods for such metadata arrays. To visualize our results with CairoMakie, we need to extract the underlying data.\n\nsliceRaw = slice.data.data\ntypeof(sliceRaw)\n\nWe can now visualize our first MPI reconstruction using MPIReco:\n\nusing CairoMakie\nfig = heatmap(sliceRaw)\nhidedecorations!(fig.axis)\nfig\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/howtos/caching/#Enable-Caching","page":"Enable Caching","title":"Enable Caching","text":"include(\"../../download.jl\") #hide\n\nImage reconstructions implemented with AbstractImageReconstruction.jl are composed of several individual processing steps which form the whole (computationally expensive) image recosntruction procses. Often time one wants to slightly modify reconstruction parameters, for example when searching for good regularization parameters. AbstractImageReconstruction.jl offers a caching option in which algorithms can reuse intermediate processing results, as long as those are unaffected by the parameter changes.\n\nThis caching mechanism has to be explicitly added in the implementation of an algorithm and an algorithms RecoPlan. All algorithms constructed from the same plan, can access the same cache. To make this behaviour available to the high-level reconstruct interface, MPIReco can cache RecoPlans between reconstructions:\n\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\"))\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\"))\nparams = Dict{Symbol, Any}()\nparams[:SNRThresh] = 5\nparams[:frames] = 1:1\nparams[:minFreq] = 80e3\nparams[:recChannels] = 1:2\nparams[:spectralLeakageCorrection] = true\nparams[:sf] = bSF\nparams[:reg] = [L2Regularization(0.1f0)];\nnothing #hide\n\nCaching is disabled by default and if you modify the blueprint of a plan, for example by providing a different weighting strategy. To opt into caching you call a reconstruction with a true flag as the third argument:\n\ninitial = @elapsed reconstruct(\"SinglePatch\", b, true; params...)\nsecond = @elapsed reconstruct(\"SinglePatch\", b, true; params...)\ninitial/second # speedup\n\nChanging a parameter which affects the cache result, in this case the loading of the system matrix, invalidates the cache:\n\nthird = @elapsed reconstruct(\"SinglePatch\", b, true; params..., SNRThresh = 2)\ninitial/third\n\nIt is possible to manually empty the MPIRecos cache of blueprints and thus release any large cached results:\n\nemptyRecoCache!();\nnothing #hide\n\nThe number of cached reconstruction plans can be set via the MPIRECO_CACHE_SIZE environment variable. Note that restarting is necessary for it to take any effect.\n\nWhen directly constructing a plan, all algorithms build from it can benefit from the plans caching:\n\nplan = MPIRecoPlan(\"SinglePatch\")\nsetAll!(plan, params)\nresults = []\nfor  in [0.1f0, 0.5f0, 1.0f0]\n  setAll!(plan, :reg, [L2Regularization()])\n  c = reconstruct(build(plan), b)\n  push!(results, c[1, :, :, 1, 1].data)\nend\nusing CairoMakie #hide\nfig = Figure();\nhidedecorations!(heatmap(fig[1, 1], results[1], axis = (title = \" = 0.1\",)).axis)\nhidedecorations!(heatmap(fig[1, 2], results[2], axis = (title = \" = 0.5\",)).axis)\nhidedecorations!(heatmap(fig[1, 3], results[3], axis = (title = \" = 1.0\",)).axis)\nfig\n\nThis type of caching bypasses MPIRecos cache and results are only freed if there is no reference to the plan available anymore:\n\nplan = nothing\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/matrixCompression/#Matrix-Compression-Techniques","page":"Compression","title":"Matrix-Compression Techniques","text":"include(\"../../download.jl\") #hide\n\nMatrix compression can significantly accelerate the reconstruction process. This is achieved by transforming the system matrix S into a different domain through a basis transformation applied to its rows.\n\nIn MPIReco.jl, matrix compression can be enabled by specifying a sparse system-matrix loading parameter and selecting the desired sparsity transformation.\n\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"7.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\",\"20211226_204612_Dice\", \"1.mdf\")) #hide\nparams = Dict{Symbol, Any}()\nparams[:SNRThresh] = 2\nparams[:frames] = 1:100\nparams[:numAverages] = 100\nparams[:minFreq] = 80e3\nparams[:recChannels] = 1:2\nparams[:iterations] = 3\nparams[:spectralLeakageCorrection] = false\nparams[:sf] = bSF;\nnothing #hide\n\nWe first reconstruct as usual:\n\ncDense = reconstruct(\"SinglePatch\", b; params...);\nnothing #hide\n\nAfterwards we use a blueprint with a sparse system-matrix loading and setting a sparsity transformation:\n\ncSparse = reconstruct(\"SinglePatchSparse\", b; params..., sparseTrafo = \"FFT\");\nnothing #hide\n\nPossible transformations are \"FFT\", \"DCT_IV\" and \"DST\".\n\nThe transformations can be restricted to the drive-field field-of-view by setting useDFFoV = true. The compression factor, which controls how many coefficients are dropped after applying the transformation, is determined by the redFactor parameter. For example, a reduction factor of redFactor = 0.01 will drop 99% of the data.\n\ncRed = reconstruct(\"SinglePatchSparse\", b; params..., sparseTrafo = \"FFT\", useDFFoV = true, redFactor = 0.01);\nnothing #hide\n\nWe can again visualize the data with CairoMakie:\n\nusing CairoMakie #hide\nfig = Figure();\nhidedecorations!(heatmap(fig[1, 1], cDense[1, :, :, 1, 1].data.data, axis = (title = \"Dense\",)).axis)\nhidedecorations!(heatmap(fig[1, 2], cSparse[1, :, :, 1, 1].data.data, axis = (title = \"Sparse\",)).axis)\nhidedecorations!(heatmap(fig[1, 3], cRed[1, :, :, 1, 1].data.data, axis = (title = \"Sparse DF FOV\",)).axis)\nfig\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/basicReconstruction/#Basic-Reconstruction","page":"Basic Reconstructions","title":"Basic Reconstruction","text":"include(\"../../download.jl\") #hide\n\nMPIReco.jl provides different reconstruction interfaces. All of the interfaces interact with RecoPlans from AbstractImageReconstruction. These are blueprints from which different algorithms can be constructed. from which different algorithms can be constructed. For more details on these blueprints, we refer to the AbstractImageReconstruction documentation.\n\nThe reconstruction algorithm in MPIReco mainly focus on system-matrix based reconstructions, where one considers an inverse problem of the form:\n\nbeginequation\n  undersetmathbfcargmin frac12vertvert mathbfSmathbfc-mathbfu vertvert_2^2 + + mathbfR(x)\nendequation\n\nwhere mathbfS is a system matrix, mathbfu is the measurement vector, and mathbfR(x) is an (optional) regularization term.\n\nMPIReco comes with a few prepared blueprints, however one can easily add and store their own blueprints. These can be new configurations of existing algorithms and parameters or even new ones developed in other packages. Such packages could provide algorithms which are not based on system-matrix reconstructions. To read more on how to write and integrate such packages, consult the How-Tos.","category":"section"},{"location":"generated/tutorials/basicReconstruction/#High-Level-Interface","page":"Basic Reconstructions","title":"High-Level Interface","text":"In the Getting Started section, we created our first MPI reconstruction as follows:\n\nusing MPIReco #hide\nbSF = MPIFile(joinpath(datadir, \"calibrations\", \"12.mdf\")) #hide\nb = MPIFile(joinpath(datadir, \"measurements\", \"20211226_203916_MultiPatch\", \"1.mdf\")) #hide\n\nc = reconstruct(\"SinglePatch\", b;\n                   SNRThresh=5,\n                   sf = bSF,\n                   frames=1:acqNumFrames(b),\n                   minFreq=80e3,\n                   recChannels=1:rxNumChannels(b),\n                   iterations=1,\n                   spectralLeakageCorrection=true);\nnothing #hide\n\n\"SinglePatch\" here refers to a blueprint for system-matrix based single-patch image reconstruction. The keyword arguments are used to set parameters defined in the blueprint.\n\nIt is also possible to provide these parameters as a dictionary. This is especially helpful if you want to reuse parameters or change parameters programmatically.\n\nparameters = Dict{Symbol, Any}()\nparameters[:SNRThresh] = 5\nparameters[:sf] = bSF\nparameters[:frames] = 1:acqNumFrames(b)\nparameters[:minFreq] = 80e3\nparameters[:recChannels] = 1:rxNumChannels(b)\nparameters[:iterations] = 1\nparameters[:spectralLeakageCorrection] = true;\nnothing #hide\n\nYou can just pass the dictionary as an argument to the reconstruct function as follows:\n\nc2 = reconstruct(\"SinglePatch\", b; parameters...)\nisapprox(c.data, c2.data)\n\nIt is also possible to combine both methods of defining parameters:\n\nc3 = reconstruct(\"SinglePatch\", b; parameters..., recChannels = 1:1)\nc3.rxNumChannels\n\nHere, we overwrote the recChannels parameter within in the dictionary.\n\nWe can retrieve a list of all available blueprints that MPIReco can find using:\n\ngetRecoPlanList()\n\nThis list returns the filenames of the blueprints. In the reconstruct call, you only need to refer to the name without an extension.\n\nTo get the full paths of each blueprint, use:\n\nplanpaths = getRecoPlanList(;full=true)\n\nYou can add custom directories for MPIReco to search for blueprints. Other packages might do this automatically when they are loaded.\n\nIt is also possible to specify a direct path to a blueprint in the reconstruct function.\n\nindex = findfirst(endswith(\"SinglePatch.toml\"), planpaths)\nc4 = reconstruct(planpaths[index], b; parameters...)\nisapprox(c.data, c4.data)","category":"section"},{"location":"generated/tutorials/basicReconstruction/#RecoPlan-Interface","page":"Basic Reconstructions","title":"RecoPlan Interface","text":"You can also directly access a blueprint via:\n\nplan = MPIRecoPlan(\"SinglePatch\")\n\nThis allows you to see all parameters associated with the blueprint and configure them individually. The keyword arguments previously mentioned apply to all parameters with the same name. Note that different parameters in different contexts can share the same name in RecoPlans.\n\nTo modify specific parameters of the plan, you can directly access its properties:\n\nplan.parameter.reco.sf = bSF\n\nAlthough we only updated the system matrix parameter, the plan now also includes derived values from the system matrix, such as the grid size.\n\nplan.parameter.reco\n\nThis worked because the SinglePatch blueprint has connections between parameters. These connections depend on the blueprint itself and are not hardcoded in MPIReco.\n\nYou can also utilize the previously created dictionary to configure the plan:\n\nsetAll!(plan, parameters)\n\nAlternatively, you can set all parameters of a specific name directly:\n\nsetAll!(plan, :iterations, 3)\n\nOnce the plan is configured, you can construct an algorithm from it using:\n\nalgo = build(plan);\nnothing #hide\n\nAfter constructing the algorithm, you can perform multiple reconstructions and reuse the algorithm with:\n\nc = reconstruct(algo, b);\nnothing #hide\n\nDepending on the algorithm, it might be faster to reconstruct multiple measurements from a RecoPlan, instead of the high-level interface. For more information on that, we refer to the How-To for caching. Algorithms are usually thread-safe, though they might not necessarily run concurrently.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"datastructures/#Data-Structures","page":"Data Structures","title":"Data Structures","text":"MPIReco contains several different groups of data structures which will be explained in more details in this and the following explanation pages. This page focuses on the core data structures used during image reconstruction, while MPIRecoPlan focuses on the blueprint mechanisms of AbstractImageReconstruction and its interaction with MPIReco. And lastly, Imaging Operators highlights the requirements and structure of the operators used during image reconstruction.","category":"section"},{"location":"datastructures/#AbstractImageReconstruction","page":"Data Structures","title":"AbstractImageReconstruction","text":"Image reconstruction using AbstractImageReconstruction.jl allows for flexible control of the reconstruction process and data flow based on individual processing steps. The flow of these steps is defined by Julia's multiple dispatch mechanism applied to algorithms, their (configuration) parameters, and the input arguments of the processing steps.\n\nabstract type AbstractImageReconstructionParameters end\n\nParameters are adjustable settings used during image reconstruction. Users can typically configure these through keyword arguments. Parameters can be nested and may contain other parameters.\n\nabstract type AbstractImageReconstructionAlgorithm end\n\nAlgorithms are the data structures responsible for executing image reconstruction and provide the context within which a given set of parameters is evaluated. Different algorithms may have slightly different implementations of a processing step for the same parameter. Algorithms are usually stateful and implement a thread-safe FIFO behavior.\n\nfunction process(algo, params, inputs...)\n  # ...\nend\n\nProcessing steps are the internal steps used during image reconstruction. Each algorithm defines the control flow for its processing steps by invoking process on itself, a parameter, and some input values, such as a file or an array of measurement data.\n\nA process can in turn invoke another process function with, for example, a different nested parameter or a changed input value. Processing can occur with either an instance of an algorithm or the type of an algorithm. The latter case represents pure processing steps, which can be easily cached and reused between subsequent image reconstructions.\n\nThe AbstractImageReconstruction.jl documentation features a complete example of how to assemble all these components into a working image reconstruction algorithm, which provides the high-level interface reconstruct(algo, data). Alternatively, one can read the implementation of the provided MPI reconstruction algorithms.","category":"section"},{"location":"datastructures/#MPIReco","page":"Data Structures","title":"MPIReco","text":"MPIReco extends the abstract types of AbstractImageReconstruction with its own type hierarchies for AbstractMPIRecoAlgorithms <: AbstractReconstructionAlgorithm and AbstractMPIRecoParameters <: AbstractReconstructionParameters. For example, the reconstruct(\"SinglePatch\", file) function constructs a SinglePatchAlgorithm, which extends AbstractSinglePatchAlgorithm, which in turn extends AbstractMPIRecoAlgorithm.\n\nThe provided parameters are roughly grouped into preprocessing parameters, which focus on loading the correct data from MDFs, and reconstruction parameters, which focus on modifying and using the output of preprocessing to construct and solve the inverse problem of image reconstruction. Finally, post-processing parameters can be applied to the resulting images. While this rough grouping is used in the provided algorithms, custom algorithms can deviate to define and combine parameters as best fits their needs.\n\nMany parameters provide a default implementation process(algoT::AbstractMPIRecoAlgorithm, param, inputs...), allowing any algorithm to invoke a standard utility, such as loading measurement data with a given filtering parameter.","category":"section"},{"location":"#MPIReco.jl","page":"Home","title":"MPIReco.jl","text":"Julia package for the reconstruction of magnetic particle imaging (MPI) data","category":"section"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"This project provides algorithms and utility functions for the reconstruction of MPI data. The project is implemented in the programming language Julia and its algorithms use the interface provided by the AbstractImageReconstruction.jl package.\n\nMPIReco contains algorithms for a variety of system matrix based reconstructions:\n\nSingle-Patch Reconstruction\nMulti-Patch Reconstruction for data that has been acquired using a focus field sequence\nMulti-Contrast Reconstruction for reconstructions using multiple system matrices\nMatrix-Compression Techniques\n\nFurthermore, the existing algorithms can easily be adapted with new data processing steps and newly created algorithms can be seamlessly integrated into MPIRecos reconstruction interface.\n\nKey features are\n\nFrequency filtering for memory efficient reconstruction. Only frequencies used during reconstructions are loaded into memory.\nDifferent solvers provided by the package RegularizedLeastSquares.jl\nHigh-level and low-level reconstruction interfaces provide maximum flexibility for the user\nFlexible algorithm definition and parametrization with AbstractImageReconstruction.jl and the possibilty to define and include custom reconstruction algorithms\nSpectral leakage correction (implemented in MPIFiles.jl)\nVendor agnostic GPU acceleration","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"Start julia and open the package mode by entering ]. Then enter\n\nadd MPIReco\n\nThis will install the packages MPIReco.jl and all its dependencies. In particular this will install the core dependencies MPIFiles, RegularizedLeastSquares and AbstractImageReconstruction.jl.","category":"section"},{"location":"#License-/-Terms-of-Usage","page":"Home","title":"License / Terms of Usage","text":"The source code of this project is licensed under the MIT license. This implies that you are free to use, share, and adapt it. However, please give appropriate credit by citing the project.","category":"section"},{"location":"#Contact","page":"Home","title":"Contact","text":"If you have problems using the software, find mistakes, or have general questions please use the issue tracker to contact us.","category":"section"},{"location":"#Contributors","page":"Home","title":"Contributors","text":"Tobias Knopp\nMartin Mddel\nNiklas Hackelberg\nPatryk Szwargulski","category":"section"}]
}
